{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydub\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice1 = pydub.AudioSegment.from_file(\"raw_data/mohamad_nematizadeh.ogg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voice1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='mohamad1.wav'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voice1.export('mohamad1.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# concat voices to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"raw_data\"\n",
    "for file in os.listdir(path):\n",
    "    name = file.split(\".\")[0]\n",
    "    if len(name.split(\"_\")) == 2:\n",
    "        result= 0\n",
    "        for f in os.listdir(path):\n",
    "            if f.split(\".\")[0].split(\"_\")[0] == name.split(\"_\")[0] :\n",
    "                result += pydub.AudioSegment.from_file(f'raw_data/{f}')\n",
    "        result.export(f\"data/{name.split('_')[0]}.ogg\")\n",
    "    else:\n",
    "        result.export(f\"data/{name}.ogg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='data/khadije.ogg'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voice_1 = pydub.AudioSegment.from_file('raw_data/azra_1.ogg')\n",
    "voice_2 = pydub.AudioSegment.from_file('raw_data/azra_2.ogg')\n",
    "\n",
    "result = voice_1 + voice_2\n",
    "\n",
    "result.export(\"data/khadije.ogg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='data/parsa.ogg'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voice_1 = pydub.AudioSegment.from_file('raw_data/parsa_1.ogg')\n",
    "voice_2 = pydub.AudioSegment.from_file('raw_data/parsa_2.ogg')\n",
    "\n",
    "result = voice_1 + voice_2\n",
    "\n",
    "result.export(\"data/parsa.ogg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='data/mona_nemati.ogg'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voice_2 = pydub.AudioSegment.from_file('raw_data/mona_nemati.m4a')\n",
    "\n",
    "result = voice_2\n",
    "\n",
    "result.export(\"data/mona_nemati.ogg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot one voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice1 = pydub.AudioSegment.from_file('dataset/abdollah/voice_3.wav')\n",
    "\n",
    "voice2 = voice1.get_array_of_samples()\n",
    "\n",
    "print(np.array(voice2).shape)\n",
    "print(len(voice2))\n",
    "plt.figure(figsize=(20,2))\n",
    "plt.plot(voice2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove silent part of voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pydub.audio_segment.AudioSegment at 0x16a9ccae950>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parts = pydub.silence.split_on_silence(voice1, min_silence_len=2000, silence_thresh=-45)\n",
    "parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add parts of non silence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tempfile._TemporaryFileWrapper at 0x16aa7499a90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = sum(parts)\n",
    "result.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('data')\n",
    "\n",
    "for file in files:\n",
    "    audio = pydub.AudioSegment.from_file(os.path.join('data', file))\n",
    "\n",
    "    # audio = audio.set_sample_width(2)\n",
    "    audio = audio.set_frame_rate(48000)\n",
    "    # audio = audio.set_channels(1)\n",
    "    chunks = pydub.silence.split_on_silence(audio, min_silence_len=2000, silence_thresh=-45)\n",
    "    result = sum(chunks)\n",
    "    file_name = file.split('.')[0]\n",
    "    result.export(os.path.join('wav_data', f'{file_name}.wav'), format=\"wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split voices to 1sec part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir('wav_data'):\n",
    "    audio = pydub.AudioSegment.from_file(os.path.join('wav_data', file))\n",
    "    chunks = pydub.utils.make_chunks(audio, 1000)\n",
    "    person_name = file.split('.')[0]\n",
    "    os.makedirs(os.path.join('dataset',person_name), exist_ok=True)\n",
    "\n",
    "    for i,chunk in enumerate(chunks):\n",
    "        if len(chunk) >= 1000:\n",
    "            chunk.export(os.path.join('dataset',person_name, f'voice_{i}.wav'), format=\"wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
