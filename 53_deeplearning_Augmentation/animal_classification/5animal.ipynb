{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZoH1RZIl0TbI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wqob6fr12n52",
        "outputId": "6dd8adb0-43aa-4fdf-9e04-e604885caf44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1194 images belonging to 5 classes.\n",
            "Found 130 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "dataset_path = \"assets/animals\"\n",
        "\n",
        "idg = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.1,\n",
        "\n",
        "    rotation_range=10,   #degree\n",
        "    zoom_range=0.1,   #percent\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "dataset_train = idg.flow_from_directory(\n",
        "    dataset_path,\n",
        "    shuffle=True,\n",
        "    # save_to_dir=\"/content/drive/MyDrive/dataset/animal_test\",\n",
        "    subset=\"training\",\n",
        "    target_size= (224,224)\n",
        ")\n",
        "\n",
        "dataset_validation = idg.flow_from_directory(\n",
        "    dataset_path,\n",
        "    shuffle=True,\n",
        "    subset=\"validation\",\n",
        "    target_size= (224,224)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 3, got 2)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32md:\\Pylearn\\53\\animal_classification\\5animal.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Pylearn/53/animal_classification/5animal.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m a,b,c\u001b[39m=\u001b[39mdataset_validation[\u001b[39m0\u001b[39m]\n",
            "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
          ]
        }
      ],
      "source": [
        "a,b=dataset_validation[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[[0.93194574 0.6234088  0.36168933]\n",
            "  [0.9059247  0.59846944 0.31378886]\n",
            "  [0.87793905 0.5740996  0.2738534 ]\n",
            "  ...\n",
            "  [0.9058824  0.72156864 0.6509804 ]\n",
            "  [0.90584344 0.7215297  0.6509415 ]\n",
            "  [0.9052695  0.7209557  0.6503675 ]]\n",
            "\n",
            " [[0.9330698  0.6250949  0.36730966]\n",
            "  [0.911545   0.60352767 0.32221934]\n",
            "  [0.88131124 0.5769097  0.27834964]\n",
            "  ...\n",
            "  [0.90287703 0.71856326 0.647975  ]\n",
            "  [0.902303   0.71798927 0.64740103]\n",
            "  [0.90196085 0.7176471  0.64705884]]\n",
            "\n",
            " [[0.93419385 0.626781   0.37292993]\n",
            "  [0.9171653  0.608586   0.33064982]\n",
            "  [0.88468343 0.5797199  0.2828459 ]\n",
            "  ...\n",
            "  [0.90196085 0.7176471  0.64705884]\n",
            "  [0.90196085 0.7176471  0.64705884]\n",
            "  [0.90196085 0.7176471  0.64705884]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.7182445  0.3260876  0.20059736]\n",
            "  [0.72054034 0.3283835  0.20289329]\n",
            "  [0.7228363  0.3306794  0.2051892 ]\n",
            "  ...\n",
            "  [0.8765938  0.90012324 0.99424094]\n",
            "  [0.87843144 0.90196085 0.9960785 ]\n",
            "  [0.88321346 0.90196085 0.99846953]]\n",
            "\n",
            " [[0.7324062  0.3402493  0.2147591 ]\n",
            "  [0.732649   0.34049213 0.21500193]\n",
            "  [0.73150104 0.33934417 0.21385396]\n",
            "  ...\n",
            "  [0.8754698  0.8989992  0.99311686]\n",
            "  [0.87843144 0.90196085 0.9960785 ]\n",
            "  [0.8820894  0.90196085 0.9979075 ]]\n",
            "\n",
            " [[0.7267161  0.33455923 0.20906901]\n",
            "  [0.7255682  0.33341128 0.20792106]\n",
            "  [0.7265603  0.3322633  0.20837818]\n",
            "  ...\n",
            "  [0.8743457  0.89787513 0.9919928 ]\n",
            "  [0.87843144 0.90196085 0.9960785 ]\n",
            "  [0.88096535 0.90196085 0.99734545]]]\n"
          ]
        }
      ],
      "source": [
        "print(a[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "w25zmLIg_SwJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "38/38 [==============================] - 45s 1s/step - loss: 1.5669 - accuracy: 0.2931 - val_loss: 1.4553 - val_accuracy: 0.3462\n",
            "Epoch 2/20\n",
            "38/38 [==============================] - 28s 740ms/step - loss: 1.3633 - accuracy: 0.3894 - val_loss: 1.2521 - val_accuracy: 0.4846\n",
            "Epoch 3/20\n",
            "38/38 [==============================] - 27s 702ms/step - loss: 1.1530 - accuracy: 0.4992 - val_loss: 1.2431 - val_accuracy: 0.4538\n",
            "Epoch 4/20\n",
            "38/38 [==============================] - 27s 711ms/step - loss: 1.0627 - accuracy: 0.5461 - val_loss: 1.1291 - val_accuracy: 0.5308\n",
            "Epoch 5/20\n",
            "38/38 [==============================] - 27s 709ms/step - loss: 0.9985 - accuracy: 0.5980 - val_loss: 1.0731 - val_accuracy: 0.5308\n",
            "Epoch 6/20\n",
            "38/38 [==============================] - 26s 698ms/step - loss: 0.8733 - accuracy: 0.6491 - val_loss: 1.0672 - val_accuracy: 0.5769\n",
            "Epoch 7/20\n",
            "38/38 [==============================] - 27s 724ms/step - loss: 0.7755 - accuracy: 0.6918 - val_loss: 1.2105 - val_accuracy: 0.5077\n",
            "Epoch 8/20\n",
            "38/38 [==============================] - 27s 711ms/step - loss: 0.7385 - accuracy: 0.7169 - val_loss: 1.0455 - val_accuracy: 0.5846\n",
            "Epoch 9/20\n",
            "38/38 [==============================] - 26s 697ms/step - loss: 0.6646 - accuracy: 0.7454 - val_loss: 1.1020 - val_accuracy: 0.5923\n",
            "Epoch 10/20\n",
            "38/38 [==============================] - 28s 748ms/step - loss: 0.6185 - accuracy: 0.7663 - val_loss: 1.1980 - val_accuracy: 0.6231\n",
            "Epoch 11/20\n",
            "38/38 [==============================] - 27s 722ms/step - loss: 0.6158 - accuracy: 0.7839 - val_loss: 1.1862 - val_accuracy: 0.5923\n",
            "Epoch 12/20\n",
            "38/38 [==============================] - 27s 706ms/step - loss: 0.5232 - accuracy: 0.8049 - val_loss: 1.1011 - val_accuracy: 0.6692\n",
            "Epoch 13/20\n",
            "38/38 [==============================] - 27s 696ms/step - loss: 0.4465 - accuracy: 0.8291 - val_loss: 1.1959 - val_accuracy: 0.6077\n",
            "Epoch 14/20\n",
            "38/38 [==============================] - 27s 717ms/step - loss: 0.3754 - accuracy: 0.8543 - val_loss: 1.1563 - val_accuracy: 0.6385\n",
            "Epoch 15/20\n",
            "38/38 [==============================] - 28s 728ms/step - loss: 0.3567 - accuracy: 0.8652 - val_loss: 1.1457 - val_accuracy: 0.6308\n",
            "Epoch 16/20\n",
            "38/38 [==============================] - 27s 704ms/step - loss: 0.3049 - accuracy: 0.8777 - val_loss: 1.3091 - val_accuracy: 0.6769\n",
            "Epoch 17/20\n",
            "38/38 [==============================] - 27s 708ms/step - loss: 0.2906 - accuracy: 0.8920 - val_loss: 1.3171 - val_accuracy: 0.6231\n",
            "Epoch 18/20\n",
            "38/38 [==============================] - 27s 720ms/step - loss: 0.3345 - accuracy: 0.8727 - val_loss: 1.1470 - val_accuracy: 0.6846\n",
            "Epoch 19/20\n",
            "38/38 [==============================] - 28s 734ms/step - loss: 0.2494 - accuracy: 0.9146 - val_loss: 1.1811 - val_accuracy: 0.6769\n",
            "Epoch 20/20\n",
            "38/38 [==============================] - 29s 751ms/step - loss: 0.2225 - accuracy: 0.9196 - val_loss: 1.5079 - val_accuracy: 0.6308\n"
          ]
        }
      ],
      "source": [
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), strides=(2, 2), activation=\"relu\", padding=\"same\", input_shape=(224, 224, 3)),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, (3, 3), strides=(2, 2), activation=\"relu\", padding=\"same\"),\n",
        "    layers.MaxPooling2D(),\n",
        "    # layers.Conv2D(128, (3, 3), strides=(1, 1), activation=\"relu\"),\n",
        "    # layers.MaxPooling2D(),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation=\"relu\"),\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(5, activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss = tf.keras.losses.categorical_crossentropy,\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "history = model.fit(dataset_train, validation_data=dataset_validation, epochs=20)\n",
        "\n",
        "model.save('weights/animals.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['cat', 'dog', 'elephant', 'giraffe', 'panda']\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002EC08C8EDE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 84ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'cat'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "\n",
        "data_folder = 'animals'\n",
        "images = []\n",
        "files = []\n",
        "feature = dict()\n",
        "featuress = []\n",
        "\n",
        "for f in os.listdir(data_folder) :\n",
        "    files.append(f)\n",
        "\n",
        "files.sort()\n",
        "print(files)\n",
        "\n",
        "model = tf.keras.models.load_model('weights/animals.h5')\n",
        "image = cv2.imread('test/cat2.jpg')\n",
        "image = cv2.resize(image, (224,224))\n",
        "image = np.array(image)/255\n",
        "# print(image.shape)\n",
        "image = np.expand_dims(image, axis=0) \n",
        "# print(image.shape)\n",
        "result = model.predict(image)\n",
        "# print(result)\n",
        "\n",
        "out = np.argmax(result)\n",
        "# print(out)\n",
        "files[out]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'dataset_validation' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32md:\\Pylearn\\53\\animal_classification\\5animal.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Pylearn/53/animal_classification/5animal.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m a,b\u001b[39m=\u001b[39m dataset_validation\n",
            "\u001b[1;31mNameError\u001b[0m: name 'dataset_validation' is not defined"
          ]
        }
      ],
      "source": [
        "a,b= dataset_validation"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
