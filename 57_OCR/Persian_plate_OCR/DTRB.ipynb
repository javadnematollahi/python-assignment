{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Clone DTRB repository from github "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAY4TNRP42Se",
        "outputId": "bcabb954-cd27-4451-f42c-730f69184d08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'deep-text-recognition-benchmark'...\n",
            "remote: Enumerating objects: 499, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 499 (delta 0), reused 1 (delta 0), pack-reused 495\u001b[K\n",
            "Receiving objects: 100% (499/499), 3.07 MiB | 7.05 MiB/s, done.\n",
            "Resolving deltas: 100% (301/301), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/clovaai/deep-text-recognition-benchmark.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5VuTq0x43_1",
        "outputId": "813d09fc-dccb-42ad-bd14-6503c6fcf924"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/deep-text-recognition-benchmark\n"
          ]
        }
      ],
      "source": [
        "%cd /content/deep-text-recognition-benchmark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract dataset that uploaded in google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q patool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94XbckYh45l1"
      },
      "outputs": [],
      "source": [
        "import patoolib\n",
        "patoolib.extract_archive(\"/content/drive/MyDrive/dataset/Persian_pelate/validation.rar\", outdir=\"/content/drive/MyDrive/dataset/Persian_pelate\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download pretrained model from google drive "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MqTMGza47pd",
        "outputId": "96a5c103-5703-4e0d-8a21-36bea4fd4b57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1b59rXuGGmKne1AuHnkgDzoYgKeETNMv9\n",
            "To: /content/deep-text-recognition-benchmark/TPS-ResNet-BiLSTM-Attn.pth\n",
            "100% 199M/199M [00:02<00:00, 92.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1b59rXuGGmKne1AuHnkgDzoYgKeETNMv9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6qy9oXl5EQF",
        "outputId": "2ade3d7b-cc2e-4e0a-d114-faf980c8e7c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ubkg7E2vGEOqS4K_quwf9Vl-i8IVpklM\n",
            "To: /content/deep-text-recognition-benchmark/plate_img-train.zip\n",
            "100% 196M/196M [00:06<00:00, 28.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1ubkg7E2vGEOqS4K_quwf9Vl-i8IVpklM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8PvTBJt5Ixt",
        "outputId": "413ab3b3-63ca-45ff-d800-4bbc061aea86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1AL5Zsg2hDqcwF8ZmR0MJTbjgXIoE5W-I\n",
            "To: /content/deep-text-recognition-benchmark/plate_img-validation.zip\n",
            "100% 27.2M/27.2M [00:00<00:00, 50.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1AL5Zsg2hDqcwF8ZmR0MJTbjgXIoE5W-I"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3shORNFW5MJ-",
        "outputId": "5c08c74b-a10d-4612-a960-8d2d3086d550"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/299.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m225.3/299.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q lmdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9KDY_aZ5Mu_",
        "outputId": "31421349-b9af-411a-944f-49241f756bc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model input parameters 32 100 20 1 512 256 38 70 TPS ResNet BiLSTM Attn\n",
            "loading pretrained model from TPS-ResNet-BiLSTM-Attn.pth\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "--------------------------------------------------------------------------------\n",
            "image_path               \tpredicted_labels         \tconfidence score\n",
            "--------------------------------------------------------------------------------\n",
            "my_image/english1.jpg    \tppz65pwo                 \t0.0168\n",
            "my_image/english2.jpg    \tintercomentalize         \t0.0000\n",
            "my_image/farsi1.jpg      \tintarvity                \t0.0543\n",
            "my_image/farsi2.jpg      \tscan                     \t0.0196\n"
          ]
        }
      ],
      "source": [
        "!python3 demo.py \\\n",
        "--Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction Attn \\\n",
        "--image_folder my_image/ --batch_max_length 70 \\\n",
        "--saved_model TPS-ResNet-BiLSTM-Attn.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQd10C3E5P52",
        "outputId": "98ef48a3-fe21-4bf7-c7a2-d4a5b333b927"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/88.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m81.9/88.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q fire"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Convert persian plate dataset to lmdb file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcbxkE6r5RqF"
      },
      "outputs": [],
      "source": [
        "!python3 create_lmdb_dataset.py --inputPath /content/drive/MyDrive/dataset/Persian_pelate --gtFile /content/drive/MyDrive/dataset/Persian_pelate/gt_train.txt --outputPath /content/drive/MyDrive/dataset/Persian_pelate/lmdb_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w63iKauT5Toe"
      },
      "outputs": [],
      "source": [
        "!python3 create_lmdb_dataset.py --inputPath /content/drive/MyDrive/dataset/Persian_pelate --gtFile /content/drive/MyDrive/dataset/Persian_pelate/gt_validation.txt --outputPath /content/drive/MyDrive/dataset/Persian_pelate/lmdb_files_validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2p-oR2BMNTGJ",
        "outputId": "0a6f67ad-69b0-4a2b-9898-594f12b4f6bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Written 1000 / 5559\n",
            "Written 2000 / 5559\n",
            "Written 3000 / 5559\n",
            "Written 4000 / 5559\n",
            "Written 5000 / 5559\n",
            "Created dataset with 5559 samples\n"
          ]
        }
      ],
      "source": [
        "!python3 create_lmdb_dataset.py --inputPath /content/drive/MyDrive/dataset/Persian_pelate --gtFile /content/drive/MyDrive/dataset/Persian_pelate/gt_test.txt --outputPath /content/drive/MyDrive/dataset/Persian_pelate/lmdb_files_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8sklTL65VlV",
        "outputId": "758ca8c9-1bc0-4ea0-c3cb-4fa8c1327217"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtering the images containing characters which are not in opt.character\n",
            "Filtering the images whose label is longer than opt.batch_max_length\n",
            "--------------------------------------------------------------------------------\n",
            "dataset_root: /content/drive/MyDrive/dataset/Persian_pelate/lmdb_files_train\n",
            "opt.select_data: ['/']\n",
            "opt.batch_ratio: ['1']\n",
            "--------------------------------------------------------------------------------\n",
            "dataset_root:    /content/drive/MyDrive/dataset/Persian_pelate/lmdb_files_train\t dataset: /\n",
            "sub-directory:\t/.\t num samples: 19358\n",
            "num total samples of /: 19358 x 1.0 (total_data_usage_ratio) = 19358\n",
            "num samples of / per batch: 192 x 1.0 (batch_ratio) = 192\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "--------------------------------------------------------------------------------\n",
            "Total_batch_size: 192 = 192\n",
            "--------------------------------------------------------------------------------\n",
            "dataset_root:    /content/drive/MyDrive/dataset/Persian_pelate/lmdb_files_validation\t dataset: /\n",
            "sub-directory:\t/.\t num samples: 2801\n",
            "--------------------------------------------------------------------------------\n",
            "model input parameters 32 100 20 1 512 256 38 25 TPS ResNet BiLSTM Attn\n",
            "Skip Transformation.LocalizationNetwork.localization_fc2.weight as it is already initialized\n",
            "Skip Transformation.LocalizationNetwork.localization_fc2.bias as it is already initialized\n",
            "Model:\n",
            "DataParallel(\n",
            "  (module): Model(\n",
            "    (Transformation): TPS_SpatialTransformerNetwork(\n",
            "      (LocalizationNetwork): LocalizationNetwork(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "          (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (6): ReLU(inplace=True)\n",
            "          (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "          (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (10): ReLU(inplace=True)\n",
            "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "          (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (14): ReLU(inplace=True)\n",
            "          (15): AdaptiveAvgPool2d(output_size=1)\n",
            "        )\n",
            "        (localization_fc1): Sequential(\n",
            "          (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "        )\n",
            "        (localization_fc2): Linear(in_features=256, out_features=40, bias=True)\n",
            "      )\n",
            "      (GridGenerator): GridGenerator()\n",
            "    )\n",
            "    (FeatureExtraction): ResNet_FeatureExtractor(\n",
            "      (ConvNet): ResNet(\n",
            "        (conv0_1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn0_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv0_2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn0_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (layer1): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (layer2): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): BasicBlock(\n",
            "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (maxpool3): MaxPool2d(kernel_size=2, stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
            "        (layer3): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (3): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (4): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (layer4): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (1): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv4_1): Conv2d(512, 512, kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), bias=False)\n",
            "        (bn4_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv4_2): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
            "        (bn4_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (AdaptiveAvgPool): AdaptiveAvgPool2d(output_size=(None, 1))\n",
            "    (SequenceModeling): Sequential(\n",
            "      (0): BidirectionalLSTM(\n",
            "        (rnn): LSTM(512, 256, batch_first=True, bidirectional=True)\n",
            "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
            "      )\n",
            "      (1): BidirectionalLSTM(\n",
            "        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
            "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (Prediction): Attention(\n",
            "      (attention_cell): AttentionCell(\n",
            "        (i2h): Linear(in_features=256, out_features=256, bias=False)\n",
            "        (h2h): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (score): Linear(in_features=256, out_features=1, bias=False)\n",
            "        (rnn): LSTMCell(294, 256)\n",
            "      )\n",
            "      (generator): Linear(in_features=256, out_features=38, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Trainable params num :  49555182\n",
            "Optimizer:\n",
            "Adadelta (\n",
            "Parameter Group 0\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    lr: 1\n",
            "    maximize: False\n",
            "    rho: 0.95\n",
            "    weight_decay: 0\n",
            ")\n",
            "------------ Options -------------\n",
            "exp_name: /content/drive/MyDrive/dataset/best_model_dtrb\n",
            "train_data: /content/drive/MyDrive/dataset/Persian_pelate/lmdb_files_train\n",
            "valid_data: /content/drive/MyDrive/dataset/Persian_pelate/lmdb_files_validation\n",
            "manualSeed: 1111\n",
            "workers: 4\n",
            "batch_size: 192\n",
            "num_iter: 16000\n",
            "valInterval: 2000\n",
            "saved_model: \n",
            "FT: False\n",
            "adam: False\n",
            "lr: 1\n",
            "beta1: 0.9\n",
            "rho: 0.95\n",
            "eps: 1e-08\n",
            "grad_clip: 5\n",
            "baiduCTC: False\n",
            "select_data: ['/']\n",
            "batch_ratio: ['1']\n",
            "total_data_usage_ratio: 1.0\n",
            "batch_max_length: 25\n",
            "imgH: 32\n",
            "imgW: 100\n",
            "rgb: False\n",
            "character: 0123456789abcdefghijklmnopqrstuvwxyz\n",
            "sensitive: False\n",
            "PAD: False\n",
            "data_filtering_off: False\n",
            "Transformation: TPS\n",
            "FeatureExtraction: ResNet\n",
            "SequenceModeling: BiLSTM\n",
            "Prediction: Attn\n",
            "num_fiducial: 20\n",
            "input_channel: 1\n",
            "output_channel: 512\n",
            "hidden_size: 256\n",
            "num_gpu: 1\n",
            "num_class: 38\n",
            "---------------------------------------\n",
            "\n",
            "[1/16000] Train loss: 3.65688, Valid loss: 3.57621, Elapsed_time: 14.24443\n",
            "Current_accuracy : 0.000, Current_norm_ED  : 0.02\n",
            "Best_accuracy    : 0.000, Best_norm_ED     : 0.02\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "45u38216                  | k2222                     | 0.0000\tFalse\n",
            "23r87598                  | kkk                       | 0.0001\tFalse\n",
            "78r43766                  | 222                       | 0.0001\tFalse\n",
            "42r68710                  | 222222222222kkkkkkkkk2222 | 0.0000\tFalse\n",
            "78n14510                  | kkkkkkkkkkkkkkkkkkkkkkkkk | 0.0000\tFalse\n",
            "--------------------------------------------------------------------------------\n",
            "[2000/16000] Train loss: 0.64781, Valid loss: 0.38995, Elapsed_time: 2085.96774\n",
            "Current_accuracy : 78.579, Current_norm_ED  : 0.94\n",
            "Best_accuracy    : 78.579, Best_norm_ED     : 0.94\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "74m72810                  | 74m72810                  | 0.9804\tTrue\n",
            "44j68711                  | 44j68711                  | 0.9374\tTrue\n",
            "32h55755                  | 32h55755                  | 0.8656\tTrue\n",
            "28j71420                  | 28j71420                  | 0.9442\tTrue\n",
            "41t27833                  | 41t27833                  | 0.8320\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "[4000/16000] Train loss: 0.05034, Valid loss: 0.50388, Elapsed_time: 4135.25202\n",
            "Current_accuracy : 80.578, Current_norm_ED  : 0.94\n",
            "Best_accuracy    : 80.578, Best_norm_ED     : 0.94\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "5v19944                   | 25v19944                  | 0.8064\tFalse\n",
            "82l82968                  | 83l82968                  | 0.9919\tFalse\n",
            "78r97418                  | 78r97418                  | 0.9978\tTrue\n",
            "92l46316                  | 92l46316                  | 0.9965\tTrue\n",
            "74w92467                  | 74w92467                  | 0.9988\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "[6000/16000] Train loss: 0.01189, Valid loss: 0.60032, Elapsed_time: 6208.92410\n",
            "Current_accuracy : 75.473, Current_norm_ED  : 0.93\n",
            "Best_accuracy    : 80.578, Best_norm_ED     : 0.94\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "92v37668                  | 92v36668                  | 0.5420\tFalse\n",
            "45b44698                  | 45b4469                   | 0.9978\tFalse\n",
            "18w52633                  | 18w52633                  | 0.9968\tTrue\n",
            "24m92810                  | 24m92810                  | 0.9873\tTrue\n",
            "77n23338                  | 77n23338                  | 0.9540\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "[8000/16000] Train loss: 0.01011, Valid loss: 0.62003, Elapsed_time: 8271.93835\n",
            "Current_accuracy : 79.829, Current_norm_ED  : 0.94\n",
            "Best_accuracy    : 80.578, Best_norm_ED     : 0.94\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "44j419                    | 94j41934                  | 0.3954\tFalse\n",
            "37n26144                  | 37n26144                  | 0.9992\tTrue\n",
            "58v16624                  | 58v16624                  | 0.9993\tTrue\n",
            "7u11916                   | 97u11916                  | 0.9563\tFalse\n",
            "31i13733                  | 31i13733                  | 0.9997\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "[10000/16000] Train loss: 0.00328, Valid loss: 0.60136, Elapsed_time: 10320.49646\n",
            "Current_accuracy : 77.615, Current_norm_ED  : 0.93\n",
            "Best_accuracy    : 80.578, Best_norm_ED     : 0.94\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "39b85855                  | 39b85855                  | 0.9988\tTrue\n",
            "76t78133                  | 76t78133                  | 0.9947\tTrue\n",
            "57q95988                  | 57q95988                  | 0.9971\tTrue\n",
            "72l92855                  | 72l92858                  | 0.2971\tFalse\n",
            "i1                        | 95887                     | 0.2272\tFalse\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "!python3 train.py \\\n",
        "--train_data /content/drive/MyDrive/dataset/Persian_pelate/lmdb_files_train --valid_data /content/drive/MyDrive/dataset/Persian_pelate/lmdb_files_validation \\\n",
        "--select_data / --batch_ratio 1  --num_iter 16000 --exp_name /content/drive/MyDrive/dataset/best_model_dtrb\\\n",
        "--Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction Attn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEPdazIxMR2n",
        "outputId": "841881af-b340-47d3-8185-715d01cb1b98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model input parameters 32 100 20 1 512 256 38 25 TPS ResNet BiLSTM Attn\n",
            "loading pretrained model from /content/drive/MyDrive/dataset/best_model_dtrb/best_accuracy.pth\n",
            "dataset_root:    /content/drive/MyDrive/dataset/Persian_pelate/lmdb_files_test\t dataset: /\n",
            "sub-directory:\t/.\t num samples: 5552\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "80.439\n"
          ]
        }
      ],
      "source": [
        "!python3 test.py \\\n",
        "--eval_data /content/drive/MyDrive/dataset/Persian_pelate/lmdb_files_test \\\n",
        "--saved_model /content/drive/MyDrive/dataset/best_model_dtrb/best_accuracy.pth \\\n",
        "--Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction Attn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Read Text on 5 test persian plate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKgnpXet5YFF",
        "outputId": "2ccbc078-cfeb-47ea-cfc4-4d3bb071aae3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model input parameters 32 100 20 1 512 256 38 8 TPS ResNet BiLSTM Attn\n",
            "loading pretrained model from /content/drive/MyDrive/dataset/best_model_dtrb/best_accuracy.pth\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "--------------------------------------------------------------------------------\n",
            "image_path               \tpredicted_labels         \tconfidence score\n",
            "--------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/dataset/5_plate_test_image/00022.jpg\t28i21255                 \t0.9970\n",
            "/content/drive/MyDrive/dataset/5_plate_test_image/00085.jpg\t68b31699                 \t0.9943\n",
            "/content/drive/MyDrive/dataset/5_plate_test_image/00192.jpg\t67e77379                 \t0.9066\n",
            "/content/drive/MyDrive/dataset/5_plate_test_image/01640.jpg\t28i21255                 \t0.9970\n",
            "/content/drive/MyDrive/dataset/5_plate_test_image/01656.jpg\t97i48912                 \t0.9799\n"
          ]
        }
      ],
      "source": [
        "!python3 demo.py \\\n",
        "--Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction Attn \\\n",
        "--image_folder /content/drive/MyDrive/dataset/5_plate_test_image --batch_max_length 8 \\\n",
        "--saved_model /content/drive/MyDrive/dataset/best_model_dtrb/best_accuracy.pth"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
